# TtalKkak AI Server - Final Requirements
# 2025년 1월 기준 RunPod에서 작동 확인된 버전
# Python 3.10, CUDA 11.8, GPU: NVIDIA RTX 6000 Ada Generation

# ===== Core Dependencies =====
torch==2.1.0+cu118
torchvision==0.16.0+cu118
torchaudio==2.1.0+cu118
numpy==1.24.4

# ===== Transformers & LLM =====
transformers==4.39.3
huggingface-hub==0.34.4
tokenizers==0.15.2
sentencepiece==0.2.0
protobuf==5.29.3
safetensors==0.5.2
accelerate==0.25.0

# ===== PEFT & LoRA =====
peft==0.7.1
bitsandbytes==0.44.2

# ===== Speech Recognition (WhisperX) =====
whisperx==3.2.0
faster-whisper==1.0.0
openai-whisper==20231117
ctranslate2==4.4.0
av==11.0.0

# ===== Speech Processing =====
pyannote.audio==3.1.1
pyannote.core==5.0.0
pyannote.database==5.1.0
pyannote.metrics==3.2.1
pyannote.pipeline==3.0.1
speechbrain==1.0.2

# ===== NLP & Text Processing =====
# BERT
klue-transformers==0.1.0  # Korean BERT

# Korean NLP
konlpy==0.6.0
mecab-python3==1.0.9
soynlp==0.0.493
python-mecab-ko==1.3.5

# Text processing
nltk==3.9.1
scikit-learn==1.6.1
scipy==1.14.1

# ===== Web Framework =====
fastapi==0.115.6
uvicorn[standard]==0.34.0
starlette==0.41.3
pydantic==2.11.7
python-multipart==0.0.20

# ===== Audio Processing =====
librosa==0.10.2.post1
soundfile==0.12.1
audioread==3.0.1
pydub==0.25.1
ffmpeg-python==0.2.0
torchaudio==2.1.0

# ===== Utilities =====
pandas==2.2.3
matplotlib==3.10.0
seaborn==0.13.2
tqdm==4.67.1
pyyaml==6.0.2
python-dotenv==1.0.1
typing-extensions==4.12.2
filelock==3.17.0

# ===== Optional (VLLM - 실패해도 무시) =====
# vllm==0.2.7  # 선택사항, CUDA 12 필요
# ray==2.9.0  # VLLM 의존성
# xformers==0.0.23.post1  # VLLM 최적화

# ===== Development Tools =====
pytest==8.3.4
black==24.11.1
isort==5.13.2
flake8==7.1.1
ipython==8.31.0
jupyter==1.1.1
notebook==7.3.2

# ===== System Dependencies (apt) =====
# 다음 시스템 패키지가 필요합니다:
# apt-get update && apt-get install -y \
#     ffmpeg \
#     libsndfile1 \
#     libgomp1 \
#     libsm6 \
#     libxext6 \
#     libxrender-dev \
#     libglib2.0-0 \
#     git \
#     wget \
#     curl \
#     unzip

# ===== Installation Order =====
# 1. pip install numpy==1.24.4
# 2. pip install torch==2.1.0+cu118 torchvision==0.16.0+cu118 torchaudio==2.1.0+cu118 --index-url https://download.pytorch.org/whl/cu118
# 3. pip install transformers==4.39.3
# 4. pip install faster-whisper==1.0.0
# 5. pip install whisperx==3.2.0
# 6. pip install -r requirements_final.txt

# ===== Verified Models =====
# WhisperX: large-v3, base (✅ 작동 확인)
# Qwen3: Qwen3-4B-Instruct-2507 (⚠️ config.json 수정 필요)
# BERT: klue/bert-base (✅ 파인튜닝 모델 작동)

# ===== Known Issues & Solutions =====
# 1. WhisperX TranscriptionOptions error
#    Solution: faster-whisper==1.0.0, whisperx==3.2.0
#
# 2. Qwen3 model_type not recognized
#    Solution: config.json에서 model_type: "qwen3" → "qwen2" 임시 변경
#    또는 trust_remote_code=True 사용
#
# 3. VLLM libcudart.so.12 error
#    Solution: VLLM 무시하고 Transformers 사용 (자동 fallback)
#
# 4. numpy version conflicts
#    Solution: numpy==1.24.4 먼저 설치

# ===== Server Info =====
# Server: http://0.0.0.0:8000
# Docs: http://0.0.0.0:8000/docs
# Health: http://0.0.0.0:8000/health
# Models Status: http://0.0.0.0:8000/models/status