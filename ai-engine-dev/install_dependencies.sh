#!/bin/bash

# =====================================
# TtalKkac AI Engine ÏùòÏ°¥ÏÑ± ÏÑ§Ïπò Ïä§ÌÅ¨Î¶ΩÌä∏
# =====================================

echo "üöÄ TtalKkac AI Engine Dependencies Installation"
echo "=============================================="

# ÏÉâÏÉÅ ÏΩîÎìú
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# OS Í∞êÏßÄ
if [[ "$OSTYPE" == "linux-gnu"* ]]; then
    OS="linux"
elif [[ "$OSTYPE" == "darwin"* ]]; then
    OS="macos"
elif [[ "$OSTYPE" == "cygwin" ]] || [[ "$OSTYPE" == "msys" ]] || [[ "$OSTYPE" == "win32" ]]; then
    OS="windows"
else
    OS="unknown"
fi

echo -e "${GREEN}Detected OS: $OS${NC}"

# Python Î≤ÑÏ†Ñ ÌôïÏù∏
PYTHON_VERSION=$(python3 --version 2>&1 | grep -Po '(?<=Python )\d+\.\d+' || python --version 2>&1 | grep -Po '(?<=Python )\d+\.\d+')
echo -e "${GREEN}Python version: $PYTHON_VERSION${NC}"

PYTHON_MAJOR=$(echo $PYTHON_VERSION | cut -d. -f1)
PYTHON_MINOR=$(echo $PYTHON_VERSION | cut -d. -f2)

if [ "$PYTHON_MAJOR" -lt 3 ] || ([ "$PYTHON_MAJOR" -eq 3 ] && [ "$PYTHON_MINOR" -lt 8 ]); then
    echo -e "${RED}Error: Python 3.8+ required${NC}"
    exit 1
fi

# CUDA Î≤ÑÏ†Ñ ÌôïÏù∏
if command -v nvidia-smi &> /dev/null; then
    CUDA_VERSION=$(nvidia-smi | grep "CUDA Version" | awk '{print $9}')
    echo -e "${GREEN}CUDA version: $CUDA_VERSION${NC}"
    HAS_GPU=true
else
    echo -e "${YELLOW}Warning: CUDA not detected. GPU acceleration will not be available.${NC}"
    HAS_GPU=false
fi

# Í∞ÄÏÉÅÌôòÍ≤Ω ÌôïÏù∏/ÏÉùÏÑ±
if [ ! -d "venv" ]; then
    read -p "Create virtual environment? (y/n): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        python3 -m venv venv || python -m venv venv
        echo -e "${GREEN}Virtual environment created${NC}"
    fi
fi

# Í∞ÄÏÉÅÌôòÍ≤Ω ÌôúÏÑ±Ìôî
if [ -d "venv" ]; then
    if [[ "$OS" == "windows" ]]; then
        source venv/Scripts/activate 2>/dev/null || ./venv/Scripts/activate
    else
        source venv/bin/activate
    fi
    echo -e "${GREEN}Virtual environment activated${NC}"
fi

# ÏãúÏä§ÌÖú Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò (Linux only)
if [[ "$OS" == "linux" ]]; then
    echo -e "${GREEN}[1/8] Installing system packages...${NC}"
    
    # root Í∂åÌïú ÌôïÏù∏
    if [ "$EUID" -eq 0 ]; then
        apt-get update
        apt-get install -y \
            ffmpeg \
            libsndfile1 \
            libportaudio2 \
            libasound2-dev \
            sox \
            libsox-fmt-all \
            git \
            git-lfs \
            build-essential \
            python3-dev
    else
        echo -e "${YELLOW}Note: Run with sudo to install system packages${NC}"
        echo "sudo apt-get install ffmpeg libsndfile1 libportaudio2 libasound2-dev sox libsox-fmt-all"
    fi
fi

# pip ÏóÖÍ∑∏Î†àÏù¥Îìú
echo -e "${GREEN}[2/8] Upgrading pip...${NC}"
pip install --upgrade pip setuptools wheel

# PyTorch ÏÑ§Ïπò
echo -e "${GREEN}[3/8] Installing PyTorch...${NC}"
if [ "$HAS_GPU" = true ]; then
    # CUDA 11.8 Î≤ÑÏ†Ñ
    pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118
else
    # CPU Î≤ÑÏ†Ñ
    pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0
fi

# Í∏∞Î≥∏ requirements ÏÑ§Ïπò
echo -e "${GREEN}[4/8] Installing main requirements...${NC}"
pip install -r requirements.txt

# WhisperX ÏÑ§Ïπò
echo -e "${GREEN}[5/8] Installing WhisperX...${NC}"
pip install git+https://github.com/m-bain/whisperx.git

# ÏÑ†ÌÉùÏ†Å Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò
if [ "$HAS_GPU" = true ]; then
    # GPU Î©îÎ™®Î¶¨ ÌôïÏù∏
    GPU_MEM=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -n 1)
    echo -e "${GREEN}GPU Memory: ${GPU_MEM}MB${NC}"
    
    if [ "$GPU_MEM" -ge 24000 ]; then
        read -p "Install VLLM for high-performance inference? (y/n): " -n 1 -r
        echo
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            echo -e "${GREEN}Installing VLLM...${NC}"
            pip install vllm==0.2.7
        fi
    fi
    
    # A100/H100 GPU ÌôïÏù∏
    GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader | head -n 1)
    if [[ "$GPU_NAME" == *"A100"* ]] || [[ "$GPU_NAME" == *"H100"* ]]; then
        read -p "Install Flash Attention for $GPU_NAME? (y/n): " -n 1 -r
        echo
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            echo -e "${GREEN}Installing Flash Attention...${NC}"
            pip install flash-attn --no-build-isolation
        fi
    fi
fi

# ÌïúÍµ≠Ïñ¥ NLP Îç∞Ïù¥ÌÑ∞ Îã§Ïö¥Î°úÎìú
echo -e "${GREEN}[6/8] Downloading Korean NLP data...${NC}"
python -c "
import nltk
import ssl
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context
    
nltk.download('punkt')
nltk.download('stopwords')
print('‚úÖ NLTK data downloaded')
" 2>/dev/null || echo -e "${YELLOW}NLTK data download skipped${NC}"

# ÏÑ§Ïπò ÌôïÏù∏
echo -e "${GREEN}[7/8] Verifying installation...${NC}"
python -c "
import sys
print('Python:', sys.version)

try:
    import torch
    print('‚úÖ PyTorch version:', torch.__version__)
    print('‚úÖ CUDA available:', torch.cuda.is_available())
    if torch.cuda.is_available():
        print('   GPU:', torch.cuda.get_device_name(0))
        print('   CUDA version:', torch.version.cuda)
except ImportError:
    print('‚ùå PyTorch not installed')

try:
    import transformers
    print('‚úÖ Transformers version:', transformers.__version__)
except ImportError:
    print('‚ùå Transformers not installed')

try:
    import whisperx
    print('‚úÖ WhisperX installed')
except ImportError:
    print('‚ö†Ô∏è  WhisperX not installed')

try:
    import fastapi
    print('‚úÖ FastAPI installed')
except ImportError:
    print('‚ùå FastAPI not installed')

try:
    import peft
    print('‚úÖ PEFT version:', peft.__version__)
except ImportError:
    print('‚ùå PEFT not installed')

try:
    import vllm
    print('‚úÖ VLLM installed')
except ImportError:
    print('‚ÑπÔ∏è  VLLM not installed (optional)')
"

# ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
echo -e "${GREEN}[8/8] Creating necessary directories...${NC}"
mkdir -p models/bert
mkdir -p models/qwen_lora
mkdir -p data
mkdir -p results
mkdir -p logs

echo ""
echo "=============================================="
echo -e "${GREEN}‚úÖ Installation completed!${NC}"
echo "=============================================="
echo ""
echo "üìã Next steps:"
echo ""
echo "1. Download/upload model files:"
echo "   ‚Ä¢ BERT: models/bert/Ttalkkac_model_v3.pt"
echo "   ‚Ä¢ LoRA: models/qwen_lora/qwen3_lora_ttalkkac_4b/"
echo ""
echo "2. Set environment variables:"
echo "   export HF_TOKEN='your-huggingface-token'"
echo "   export NGROK_AUTH_TOKEN='your-ngrok-token'"  
echo ""
echo "3. Configure settings (optional):"
echo "   cp .env.example .env"
echo "   # Edit .env file with your settings"
echo ""
echo "4. Run the server:"
echo "   python ai_server_final_with_triplets.py"
echo ""
echo "5. Test the API:"
echo "   curl http://localhost:8000/health"
echo "=============================================="

# Î¨∏Ï†ú Ìï¥Í≤∞ ÌåÅ
if [ "$HAS_GPU" = false ]; then
    echo ""
    echo -e "${YELLOW}‚ö†Ô∏è  No GPU detected. The server will run in CPU mode.${NC}"
    echo "   Performance will be significantly slower."
fi

# ffmpeg ÌôïÏù∏
if ! command -v ffmpeg &> /dev/null; then
    echo ""
    echo -e "${YELLOW}‚ö†Ô∏è  ffmpeg not found. Audio processing may not work.${NC}"
    if [[ "$OS" == "linux" ]]; then
        echo "   Install: sudo apt-get install ffmpeg"
    elif [[ "$OS" == "macos" ]]; then
        echo "   Install: brew install ffmpeg"
    elif [[ "$OS" == "windows" ]]; then
        echo "   Download from: https://ffmpeg.org/download.html"
    fi
fi