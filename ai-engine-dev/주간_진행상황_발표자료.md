# 🚀 TtalKkac 회의록 분석 AI 모델 개발 진행상황

## 📋 프로젝트 개요

**목표**: 회의록을 분석하여 체계적인 노션 프로젝트 기획안을 생성하는 AI 모델 개발

**핵심 접근법**: 
- OpenAI API 기반 골드 스탠다드 제작
- 자체 검증 시스템 구축
- 다양한 모델 크기별 파인튜닝 및 성능 비교

---

## 🎯 1. 골드 스탠다드 제작 시스템

### ✨ 주요 기능

#### 📊 **자체 스코어링 검증 시스템**
- OpenAI GPT-4o 활용한 품질 평가
- **7점 이상 자동 저장** (10점 만점)
- 반복 개선 시스템 (최대 3회 개선)
- 마지막 검증 단계 제거로 **비용 최적화**

#### ✂️ **스마트 청킹 시스템**
```
📏 청킹 규격: 5000자 기준, 512자 오버랩
🎯 분할 방식: 문장 끝에서 자연스럽게 분할
📦 결과: 각 청크별 독립적인 골드 스탠다드 생성
```

#### 🧠 **고도화된 프롬프트 엔지니어링**
- `meeting_analysis_prompts.py` 활용
- 전문가 역할 정의 시스템 프롬프트
- 구체적 작업 요구사항 명시
- Korean Business Context 최적화

### 📈 **생성 결과**
- **PRD 생성 제거** → 노션 프로젝트만 집중
- 청킹을 통한 **학습 데이터 확장**
- 품질 보장된 골드 스탠다드 확보

---

## 🔧 2. 파인튜닝 시스템 구축

### 🎨 **데이터 파이프라인**

```mermaid
flowchart LR
    A[원본 회의록] --> B[BERT 전처리]
    B --> C[5000자 청킹]
    C --> D[고도화 프롬프트]
    D --> E[골드 스탠다드]
    E --> F[파인튜닝 데이터]
```

### ⚙️ **기술적 구현**

#### **프롬프트 통일성**
- 골드 스탠다드 생성과 **100% 동일한 프롬프트**
- `generate_meeting_analysis_system_prompt()`
- `generate_meeting_analysis_user_prompt()`

#### **청킹 일치성**
- 골드 스탠다드와 **동일한 청킹 방식**
- 5000자 기준, 512자 오버랩
- 청크 인덱스 기반 정확한 매칭

#### **모델 지원 범위**
| 모델 크기 | 모델명 | 용도 |
|----------|--------|------|
| 1.4B | Qwen2.5-1.4B-Instruct | 경량화 테스트 |
| 4B | Qwen2.5-4B-Instruct | 실용성 검증 |
| 8B | Qwen2.5-8B-Instruct | 성능 최적화 |
| 14B | Qwen2.5-14B-Instruct | 최대 성능 |

---

## 📊 3. 성능 평가 계획

### 🎯 **평가 대상 모델 (총 8개)**

#### **베이스라인 모델 (4개)**
- Qwen2.5-1.4B-Instruct
- Qwen2.5-4B-Instruct  
- Qwen2.5-8B-Instruct
- Qwen2.5-14B-Instruct

#### **파인튜닝 모델 (4개)**
- Qwen2.5-1.4B-Instruct-LoRA
- Qwen2.5-4B-Instruct-LoRA
- Qwen2.5-8B-Instruct-LoRA
- Qwen2.5-14B-Instruct-LoRA

### 📏 **평가 메트릭**

#### **1. 유사도 점수 측정**
```python
- 텍스트 유사도 (코사인 유사도)
- 구조적 유사도 (JSON 스키마 일치율)
- 의미적 유사도 (임베딩 기반)
```

#### **2. 자체 프롬프트 스코어링**
```python
- 회의 내용 반영도 (1-10점)
- 프로젝트 구조 완성도 (1-10점)
- 실무 활용 가능성 (1-10점)
- 논리적 일관성 (1-10점)
```

### 📋 **평가 프로세스**
1. **동일 회의록** → 8개 모델 각각 실행
2. **결과 수집** → 골드 스탠다드와 비교
3. **점수 산출** → 유사도 + 자체 스코어링
4. **성능 분석** → 모델 크기별/파인튜닝 효과 분석

---

## 🏆 4. 주요 기술적 성과

### ✅ **시스템 최적화**
- [x] 골드 스탠다드 자동 품질 검증
- [x] 청킹 기반 데이터 확장
- [x] 프롬프트-파인튜닝 일치성 보장
- [x] 다중 모델 크기 지원

### ✅ **비용 효율성**
- [x] 7점 이상 자동 저장으로 API 호출 감소
- [x] PRD 생성 제거로 토큰 사용량 절약
- [x] 청킹을 통한 긴 텍스트 처리 최적화

### ✅ **확장성**
- [x] 모듈화된 프롬프트 시스템
- [x] 청킹 크기 조정 가능
- [x] 다양한 모델 아키텍처 지원
- [x] 평가 메트릭 커스터마이징

---

## 🎯 5. 다음 주 계획

### 📅 **1단계: 실험 실행**
- [ ] 8개 모델별 회의록 생성 실험
- [ ] 결과 데이터 수집 및 정리
- [ ] 초기 성능 분석

### 📅 **2단계: 평가 시스템 구축**
- [ ] 유사도 측정 자동화 도구 개발
- [ ] 자체 스코어링 시스템 구현
- [ ] 시각화 대시보드 구축

### 📅 **3단계: 성능 분석**
- [ ] 모델 크기별 성능 비교
- [ ] 파인튜닝 효과 정량 분석
- [ ] 최적 모델 선정 및 권장사항 도출

---

## 💡 6. 기대 효과

### 🎯 **성능 향상 예상**
- **파인튜닝 효과**: 골드 스탠다드 기반 품질 향상
- **일관성 개선**: 동일 프롬프트 사용으로 예측 가능한 결과
- **효율성 증대**: 청킹을 통한 긴 회의록 처리 능력

### 📊 **비즈니스 임팩트**
- **실용성**: 실제 회의록에서 바로 활용 가능한 기획안 생성
- **확장성**: 다양한 회의 유형에 대응 가능
- **자동화**: 수동 기획안 작성 시간 대폭 단축

---

## 🔍 7. 기술 스택

### 🛠️ **Core Technologies**
- **AI Models**: OpenAI GPT-4o, Qwen2.5 Series
- **Fine-tuning**: LoRA (Low-Rank Adaptation)
- **Data Processing**: BERT Preprocessing Pipeline
- **Evaluation**: Custom Scoring + Similarity Metrics

### 💻 **Implementation**
- **Language**: Python
- **Frameworks**: Transformers, PEFT, Datasets
- **APIs**: OpenAI API
- **Storage**: JSON-based Gold Standard Storage

---

*📝 발표일: $(date +%Y-%m-%d)*
*👨‍💻 발표자: TtalKkac Team*