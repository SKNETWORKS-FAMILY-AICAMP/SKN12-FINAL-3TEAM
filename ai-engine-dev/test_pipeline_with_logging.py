"""
Îã®Í≥ÑÎ≥Ñ Í≤∞Í≥º Ï†ÄÏû• Í∏∞Îä•Ïù¥ Ï∂îÍ∞ÄÎêú ÌÖåÏä§Ìä∏ Ïä§ÌÅ¨Î¶ΩÌä∏
Í∞Å Ï≤òÎ¶¨ Îã®Í≥ÑÏùò Í≤∞Í≥ºÎ•º JSON ÌååÏùºÎ°ú Ï†ÄÏû•
"""

import os
import json
import asyncio
import aiohttp
import logging
from datetime import datetime
from pathlib import Path
import time

# Î°úÍπÖ ÏÑ§Ï†ï
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Í≤∞Í≥º Ï†ÄÏû• ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
RESULT_DIR = Path("C:/Users/SH/Desktop/TtalKkac/ai-engine-dev/pipeline_results")
RESULT_DIR.mkdir(exist_ok=True)

# ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑÎ°ú Í≥†Ïú† Ìè¥Îçî ÏÉùÏÑ±
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
SESSION_DIR = RESULT_DIR / f"session_{timestamp}"
SESSION_DIR.mkdir(exist_ok=True)

def save_step_result(step_name: str, data: dict, step_number: int):
    """Í∞Å Îã®Í≥ÑÎ≥Ñ Í≤∞Í≥ºÎ•º JSON ÌååÏùºÎ°ú Ï†ÄÏû•"""
    filename = SESSION_DIR / f"step{step_number}_{step_name}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    logger.info(f"‚úÖ Saved {step_name} to {filename}")
    return filename

async def test_pipeline():
    """AI ÌååÏù¥ÌîÑÎùºÏù∏ ÌÖåÏä§Ìä∏ with Îã®Í≥ÑÎ≥Ñ Ï†ÄÏû•"""
    
    # ÌÖåÏä§Ìä∏ ÌååÏùº Í≤ΩÎ°ú
    audio_file = "C:/Users/SH/Desktop/TtalKkac/ai-engine-dev/test.MP3"
    
    if not os.path.exists(audio_file):
        logger.error(f"‚ùå Audio file not found: {audio_file}")
        return
    
    # AI ÏÑúÎ≤Ñ URL (Î°úÏª¨ ÎòêÎäî RunPod)
    SERVER_URL = "http://localhost:8000"  # ÎòêÎäî RunPod URL
    
    try:
        logger.info(f"üöÄ Starting pipeline test with: {audio_file}")
        logger.info(f"üìÅ Results will be saved to: {SESSION_DIR}")
        
        async with aiohttp.ClientSession() as session:
            
            # ========== STEP 1: WhisperX Ï†ÑÏÇ¨ ==========
            logger.info("\nüìù STEP 1: WhisperX Transcription...")
            
            with open(audio_file, 'rb') as f:
                data = aiohttp.FormData()
                data.add_field('audio', f, filename='test.mp3', content_type='audio/mpeg')
                
                async with session.post(f"{SERVER_URL}/transcribe", data=data) as resp:
                    if resp.status == 200:
                        result = await resp.json()
                        
                        # Step 1 Í≤∞Í≥º Ï†ÄÏû•
                        step1_data = {
                            "success": result.get("success"),
                            "full_text": result.get("transcription", {}).get("full_text", ""),
                            "segments": result.get("transcription", {}).get("segments", []),
                            "duration": result.get("transcription", {}).get("duration", 0),
                            "language": result.get("transcription", {}).get("language", "ko")
                        }
                        save_step_result("whisperx_transcription", step1_data, 1)
                        
                        # Ï†ÑÏÇ¨Îêú ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú
                        transcript = result.get("transcription", {}).get("full_text", "")
                        logger.info(f"‚úÖ Transcription completed: {len(transcript)} characters")
                    else:
                        logger.error(f"‚ùå Transcription failed: {resp.status}")
                        return
            
            # ========== STEP 2: Enhanced Transcription (Triplet + BERT) ==========
            logger.info("\nüî¨ STEP 2: Enhanced Transcription with Triplet + BERT...")
            
            with open(audio_file, 'rb') as f:
                data = aiohttp.FormData()
                data.add_field('audio', f, filename='test.mp3', content_type='audio/mpeg')
                data.add_field('enable_bert_filtering', 'true')
                data.add_field('save_noise_log', 'true')
                
                async with session.post(f"{SERVER_URL}/transcribe-enhanced", data=data) as resp:
                    if resp.status == 200:
                        result = await resp.json()
                        
                        # Step 2: BERT Ï†ÑÏ≤òÎ¶¨ Í≤∞Í≥º Ï†ÄÏû•
                        step2_data = {
                            "success": result.get("success"),
                            "original_text": result.get("transcription", {}).get("full_text", ""),
                            "triplet_data": result.get("triplet_data", {}),
                            "processing_stats": result.get("processing_stats", {})
                        }
                        save_step_result("bert_preprocessing", step2_data, 2)
                        
                        # Step 3: BERT Î∂ÑÎ•ò Í≤∞Í≥º Ï†ÄÏû•
                        step3_data = {
                            "filtered_transcript": result.get("filtered_transcript", ""),
                            "noise_segments": result.get("triplet_data", {}).get("noise_segments", []),
                            "valid_segments": result.get("triplet_data", {}).get("valid_segments", []),
                            "filtering_ratio": result.get("processing_stats", {}).get("filtering_ratio", 0)
                        }
                        save_step_result("bert_classification", step3_data, 3)
                        
                        # ÌïÑÌÑ∞ÎßÅÎêú ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú
                        filtered_text = result.get("filtered_transcript", transcript)
                        logger.info(f"‚úÖ Filtering completed: {len(transcript)} ‚Üí {len(filtered_text)} characters")
                    else:
                        logger.error(f"‚ùå Enhanced transcription failed: {resp.status}")
                        filtered_text = transcript
            
            # ========== STEP 4: LLM ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ ÌõÑÏ≤òÎ¶¨ ==========
            logger.info("\nüîß STEP 4: Post-processing for LLM input...")
            
            # 4-1: ÌÖçÏä§Ìä∏ Ï†ïÏ†ú (Ï§ëÎ≥µ Ï†úÍ±∞, Î¨∏Ïû• Ï†ïÎ¶¨)
            # Ïó∞ÏÜçÎêú Í≥µÎ∞± Ï†úÍ±∞
            cleaned_text = ' '.join(filtered_text.split())
            
            # Î¨∏Ïû• ÎÅù Ï†ïÎ¶¨ (ÎßàÏπ®Ìëú ÌôïÏù∏)
            sentences = cleaned_text.split('.')
            cleaned_sentences = []
            for sent in sentences:
                sent = sent.strip()
                if sent and len(sent) > 5:  # ÎÑàÎ¨¥ ÏßßÏùÄ Î¨∏Ïû• Ï†úÍ±∞
                    cleaned_sentences.append(sent + '.')
            
            refined_text = ' '.join(cleaned_sentences)
            
            # 4-2: Íµ¨Ï°∞Ìôî (ÏÑπÏÖò Î∂ÑÌï†, Ï£ºÏ†ú Í∑∏Î£πÌïë)
            # Îã®ÎùΩ Î∂ÑÌï† (Îπà Ï§Ñ ÎòêÎäî Ï£ºÏ†ú Î≥ÄÌôî Í∞êÏßÄ)
            paragraphs = []
            current_para = []
            
            for sent in cleaned_sentences:
                current_para.append(sent)
                # Îã®ÎùΩ Íµ¨Î∂Ñ Î°úÏßÅ (Ïòà: 5Î¨∏Ïû•ÎßàÎã§ ÎòêÎäî ÌäπÏ†ï ÌÇ§ÏõåÎìú)
                if len(current_para) >= 5 or any(kw in sent for kw in ['Îã§ÏùåÏúºÎ°ú', 'Í∑∏Î¶¨Í≥†', 'Í≤∞Î°†Ï†ÅÏúºÎ°ú']):
                    paragraphs.append(' '.join(current_para))
                    current_para = []
            
            if current_para:
                paragraphs.append(' '.join(current_para))
            
            # 4-3: Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
            structured_input = {
                "context": "ÌöåÏùò ÎÖπÏ∑®Î°ù Î∂ÑÏÑù",
                "timestamp": datetime.now().isoformat(),
                "content": refined_text,
                "paragraphs": paragraphs,
                "metadata": {
                    "sentence_count": len(cleaned_sentences),
                    "paragraph_count": len(paragraphs),
                    "avg_sentence_length": sum(len(s) for s in cleaned_sentences) / len(cleaned_sentences) if cleaned_sentences else 0
                }
            }
            
            # 4-4: ÌÜ†ÌÅ∞ ÏµúÏ†ÅÌôî Î∞è Ï≤≠ÌÇπ Ï§ÄÎπÑ
            estimated_tokens = len(refined_text) * 1.5  # ÌïúÍ∏Ä Í∏∞Ï§Ä ÎåÄÎûµÏ†Å Ï∂îÏ†ï
            max_context = 28000  # ÏïàÏ†Ñ ÎßàÏßÑ Í≥†Î†§
            
            chunks = []
            if estimated_tokens > max_context:
                # Ï≤≠ÌÇπ ÌïÑÏöî
                chunk_size = int(max_context / 1.5)  # ÌÜ†ÌÅ∞ Í∏∞Ï§Ä
                text_chunk_size = int(chunk_size / 1.5)  # Î¨∏Ïûê Í∏∞Ï§Ä Ïó≠ÏÇ∞
                
                current_chunk = ""
                for para in paragraphs:
                    if len(current_chunk) + len(para) < text_chunk_size:
                        current_chunk += para + "\n\n"
                    else:
                        chunks.append(current_chunk.strip())
                        current_chunk = para + "\n\n"
                
                if current_chunk:
                    chunks.append(current_chunk.strip())
            else:
                chunks = [refined_text]
            
            step4_data = {
                "original_filtered_text": filtered_text,
                "refined_text": refined_text,
                "structured_input": structured_input,
                "chunks": chunks,
                "chunk_count": len(chunks),
                "postprocessing_stats": {
                    "original_length": len(filtered_text),
                    "refined_length": len(refined_text),
                    "sentence_count": len(cleaned_sentences),
                    "paragraph_count": len(paragraphs),
                    "estimated_tokens": estimated_tokens,
                    "chunking_required": len(chunks) > 1
                },
                "optimization": {
                    "duplicate_removal": True,
                    "sentence_cleaning": True,
                    "paragraph_structuring": True,
                    "token_optimization": True
                }
            }
            save_step_result("llm_postprocessing", step4_data, 4)
            
            logger.info(f"‚úÖ LLM post-processing completed:")
            logger.info(f"   - Sentences: {len(cleaned_sentences)}")
            logger.info(f"   - Paragraphs: {len(paragraphs)}")
            logger.info(f"   - Chunks: {len(chunks)}")
            logger.info(f"   - Text reduction: {len(filtered_text)} ‚Üí {len(refined_text)} chars")
            
            # LLMÏóê Ï†ÑÎã¨Ìï† ÏµúÏ¢Ö ÌÖçÏä§Ìä∏
            llm_input_text = refined_text
            
            # ========== STEP 5: ÌöåÏùòÎ°ù ÏÉùÏÑ± (ÎÖ∏ÏÖò Í∏∞ÌöçÏïà) ==========
            logger.info("\nüìã STEP 5: Generating meeting minutes (Notion project)...")
            
            async with session.post(
                f"{SERVER_URL}/generate-notion-project",
                json={
                    "transcript": llm_input_text,  # ÌõÑÏ≤òÎ¶¨Îêú ÌÖçÏä§Ìä∏ ÏÇ¨Ïö©
                    "num_tasks": 5,
                    "additional_context": "ÏûêÎèô ÏÉùÏÑ±Îêú ÌöåÏùòÎ°ù"
                }
            ) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    
                    # Step 5: ÌöåÏùòÎ°ù Í≤∞Í≥º Ï†ÄÏû•
                    step5_data = {
                        "success": result.get("success"),
                        "notion_project": result.get("notion_project", {}),
                        "formatted_notion": result.get("formatted_notion", ""),
                        "metadata": {
                            "generated_at": datetime.now().isoformat(),
                            "source_text_length": len(filtered_text)
                        }
                    }
                    save_step_result("meeting_minutes", step5_data, 5)
                    
                    notion_project = result.get("notion_project", {})
                    logger.info(f"‚úÖ Meeting minutes generated: {notion_project.get('projectName', 'Unknown')}")
                else:
                    logger.error(f"‚ùå Meeting minutes generation failed: {resp.status}")
                    notion_project = {}
            
            # ========== STEP 6: Task Î∞è SubTask ÏÉùÏÑ± ==========
            logger.info("\nüéØ STEP 6: Generating tasks and subtasks...")
            
            # Ï†ÑÏ≤¥ ÌååÏù¥ÌîÑÎùºÏù∏ Ïã§Ìñâ
            async with session.post(
                f"{SERVER_URL}/two-stage-pipeline-text",
                json={
                    "transcript": llm_input_text,  # ÌõÑÏ≤òÎ¶¨Îêú ÌÖçÏä§Ìä∏ ÏÇ¨Ïö©
                    "generate_notion": True,
                    "generate_tasks": True,
                    "num_tasks": 5
                }
            ) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    
                    # Step 6: Task Í≤∞Í≥º Ï†ÄÏû•
                    tasks_data = result.get("stage3_tasks", {})
                    if isinstance(tasks_data, dict) and "action_items" in tasks_data:
                        tasks_list = tasks_data.get("action_items", [])
                    else:
                        tasks_list = []
                    
                    step6_data = {
                        "success": result.get("success"),
                        "tasks": tasks_list,
                        "task_count": len(tasks_list),
                        "subtask_count": sum(len(task.get("subtasks", [])) for task in tasks_list),
                        "complexity_analysis": result.get("complexity_analysis", {}),
                        "processing_time": result.get("processing_time", 0),
                        "metadata": {
                            "generated_at": datetime.now().isoformat(),
                            "pipeline_version": "2-stage-with-triplet"
                        }
                    }
                    save_step_result("tasks_and_subtasks", step6_data, 6)
                    
                    logger.info(f"‚úÖ Generated {step6_data['task_count']} tasks with {step6_data['subtask_count']} subtasks")
                else:
                    logger.error(f"‚ùå Task generation failed: {resp.status}")
            
            # ========== ÏµúÏ¢Ö ÏöîÏïΩ ==========
            logger.info("\n" + "="*60)
            logger.info("üìä PIPELINE EXECUTION SUMMARY")
            logger.info("="*60)
            logger.info(f"‚úÖ All results saved to: {SESSION_DIR}")
            logger.info(f"   - Step 1: WhisperX transcription")
            logger.info(f"   - Step 2: BERT preprocessing")
            logger.info(f"   - Step 3: BERT classification")
            logger.info(f"   - Step 4: LLM preprocessing")
            logger.info(f"   - Step 5: Meeting minutes")
            logger.info(f"   - Step 6: Tasks and subtasks")
            
            # Ï†ÑÏ≤¥ ÏöîÏïΩ ÌååÏùº ÏÉùÏÑ±
            summary = {
                "session_id": timestamp,
                "audio_file": audio_file,
                "pipeline_steps": [
                    "whisperx_transcription",
                    "bert_preprocessing",
                    "bert_classification",
                    "llm_preprocessing",
                    "meeting_minutes",
                    "tasks_and_subtasks"
                ],
                "results_directory": str(SESSION_DIR),
                "execution_time": datetime.now().isoformat()
            }
            
            summary_file = SESSION_DIR / "pipeline_summary.json"
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            
            logger.info(f"\nüìÑ Summary saved to: {summary_file}")
            
    except Exception as e:
        logger.error(f"‚ùå Pipeline error: {e}")
        import traceback
        traceback.print_exc()

async def main():
    """Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò"""
    logger.info("üöÄ Starting TtalKkak AI Pipeline Test")
    logger.info(f"üìÅ Results will be saved to: {RESULT_DIR}")
    
    # ÏÑúÎ≤Ñ ÏÉÅÌÉú Ï≤¥ÌÅ¨
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get("http://localhost:8000/health") as resp:
                if resp.status == 200:
                    health = await resp.json()
                    logger.info(f"‚úÖ Server is healthy: {health}")
                else:
                    logger.error("‚ùå Server is not responding")
                    return
    except Exception as e:
        logger.error(f"‚ùå Cannot connect to server: {e}")
        logger.info("üí° Please make sure the AI server is running:")
        logger.info("   cd ai-engine-dev && python ai_server_final_with_triplets.py")
        return
    
    # ÌååÏù¥ÌîÑÎùºÏù∏ Ïã§Ìñâ
    await test_pipeline()

if __name__ == "__main__":
    # WindowsÏóêÏÑú Ïù¥Î≤§Ìä∏ Î£®ÌîÑ Ï†ïÏ±Ö ÏÑ§Ï†ï
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    # Ïã§Ìñâ
    asyncio.run(main())