"""
ë‹¨ê³„ë³„ ê²°ê³¼ ì €ì¥ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê° ì²˜ë¦¬ ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
"""

import os
import json
import asyncio
import aiohttp
import logging
from datetime import datetime
from pathlib import Path
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
RESULT_DIR = Path("C:/Users/SH/Desktop/TtalKkac/ai-engine-dev/pipeline_results")
RESULT_DIR.mkdir(exist_ok=True)

# íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ê³ ìœ  í´ë” ìƒì„±
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
SESSION_DIR = RESULT_DIR / f"session_{timestamp}"
SESSION_DIR.mkdir(exist_ok=True)

def save_step_result(step_name: str, data: dict, step_number: int):
    """ê° ë‹¨ê³„ë³„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    filename = SESSION_DIR / f"step{step_number}_{step_name}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    logger.info(f"âœ… Saved {step_name} to {filename}")
    return filename

async def test_pipeline():
    """AI íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ with ë‹¨ê³„ë³„ ì €ì¥"""
    
    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
    audio_file = "C:/Users/SH/Desktop/TtalKkac/ai-engine-dev/test.MP3"
    
    if not os.path.exists(audio_file):
        logger.error(f"âŒ Audio file not found: {audio_file}")
        return
    
    # AI ì„œë²„ URL (ë¡œì»¬ ë˜ëŠ” RunPod)
    SERVER_URL = "http://localhost:8000"  # ë˜ëŠ” RunPod URL
    
    try:
        logger.info(f"ğŸš€ Starting pipeline test with: {audio_file}")
        logger.info(f"ğŸ“ Results will be saved to: {SESSION_DIR}")
        
        async with aiohttp.ClientSession() as session:
            
            # ========== STEP 1: WhisperX ì „ì‚¬ ==========
            logger.info("\nğŸ“ STEP 1: WhisperX Transcription...")
            
            with open(audio_file, 'rb') as f:
                data = aiohttp.FormData()
                data.add_field('audio', f, filename='test.mp3', content_type='audio/mpeg')
                
                async with session.post(f"{SERVER_URL}/transcribe", data=data) as resp:
                    if resp.status == 200:
                        result = await resp.json()
                        
                        # Step 1 ê²°ê³¼ ì €ì¥
                        step1_data = {
                            "success": result.get("success"),
                            "full_text": result.get("transcription", {}).get("full_text", ""),
                            "segments": result.get("transcription", {}).get("segments", []),
                            "duration": result.get("transcription", {}).get("duration", 0),
                            "language": result.get("transcription", {}).get("language", "ko")
                        }
                        save_step_result("whisperx_transcription", step1_data, 1)
                        
                        # ì „ì‚¬ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        transcript = result.get("transcription", {}).get("full_text", "")
                        logger.info(f"âœ… Transcription completed: {len(transcript)} characters")
                    else:
                        logger.error(f"âŒ Transcription failed: {resp.status}")
                        return
            
            # ========== STEP 2: Enhanced Transcription (Triplet + BERT) ==========
            logger.info("\nğŸ”¬ STEP 2: Enhanced Transcription with Triplet + BERT...")
            
            with open(audio_file, 'rb') as f:
                data = aiohttp.FormData()
                data.add_field('audio', f, filename='test.mp3', content_type='audio/mpeg')
                data.add_field('enable_bert_filtering', 'true')
                data.add_field('save_noise_log', 'true')
                
                async with session.post(f"{SERVER_URL}/transcribe-enhanced", data=data) as resp:
                    if resp.status == 200:
                        result = await resp.json()
                        
                        # Step 2: BERT ì „ì²˜ë¦¬ ê²°ê³¼ ì €ì¥
                        step2_data = {
                            "success": result.get("success"),
                            "original_text": result.get("transcription", {}).get("full_text", ""),
                            "triplet_data": result.get("triplet_data", {}),
                            "processing_stats": result.get("processing_stats", {})
                        }
                        save_step_result("bert_preprocessing", step2_data, 2)
                        
                        # Step 3: BERT ë¶„ë¥˜ ê²°ê³¼ ì €ì¥
                        step3_data = {
                            "filtered_transcript": result.get("filtered_transcript", ""),
                            "noise_segments": result.get("triplet_data", {}).get("noise_segments", []),
                            "valid_segments": result.get("triplet_data", {}).get("valid_segments", []),
                            "filtering_ratio": result.get("processing_stats", {}).get("filtering_ratio", 0)
                        }
                        save_step_result("bert_classification", step3_data, 3)
                        
                        # í•„í„°ë§ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        filtered_text = result.get("filtered_transcript", transcript)
                        logger.info(f"âœ… Filtering completed: {len(transcript)} â†’ {len(filtered_text)} characters")
                    else:
                        logger.error(f"âŒ Enhanced transcription failed: {resp.status}")
                        filtered_text = transcript
            
            # ========== STEP 4: LLM ì…ë ¥ ë°ì´í„° í›„ì²˜ë¦¬ ==========
            logger.info("\nğŸ”§ STEP 4: Post-processing for LLM input...")
            
            # 4-1: í…ìŠ¤íŠ¸ ì •ì œ (ì¤‘ë³µ ì œê±°, ë¬¸ì¥ ì •ë¦¬)
            # ì—°ì†ëœ ê³µë°± ì œê±°
            cleaned_text = ' '.join(filtered_text.split())
            
            # ë¬¸ì¥ ë ì •ë¦¬ (ë§ˆì¹¨í‘œ í™•ì¸)
            sentences = cleaned_text.split('.')
            cleaned_sentences = []
            for sent in sentences:
                sent = sent.strip()
                if sent and len(sent) > 5:  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ ì œê±°
                    cleaned_sentences.append(sent + '.')
            
            refined_text = ' '.join(cleaned_sentences)
            
            # 4-2: êµ¬ì¡°í™” (ì„¹ì…˜ ë¶„í• , ì£¼ì œ ê·¸ë£¹í•‘)
            # ë‹¨ë½ ë¶„í•  (ë¹ˆ ì¤„ ë˜ëŠ” ì£¼ì œ ë³€í™” ê°ì§€)
            paragraphs = []
            current_para = []
            
            for sent in cleaned_sentences:
                current_para.append(sent)
                # ë‹¨ë½ êµ¬ë¶„ ë¡œì§ (ì˜ˆ: 5ë¬¸ì¥ë§ˆë‹¤ ë˜ëŠ” íŠ¹ì • í‚¤ì›Œë“œ)
                if len(current_para) >= 5 or any(kw in sent for kw in ['ë‹¤ìŒìœ¼ë¡œ', 'ê·¸ë¦¬ê³ ', 'ê²°ë¡ ì ìœ¼ë¡œ']):
                    paragraphs.append(' '.join(current_para))
                    current_para = []
            
            if current_para:
                paragraphs.append(' '.join(current_para))
            
            # 4-3: ë©”íƒ€ë°ì´í„° ì¶”ê°€
            structured_input = {
                "context": "íšŒì˜ ë…¹ì·¨ë¡ ë¶„ì„",
                "timestamp": datetime.now().isoformat(),
                "content": refined_text,
                "paragraphs": paragraphs,
                "metadata": {
                    "sentence_count": len(cleaned_sentences),
                    "paragraph_count": len(paragraphs),
                    "avg_sentence_length": sum(len(s) for s in cleaned_sentences) / len(cleaned_sentences) if cleaned_sentences else 0
                }
            }
            
            # 4-4: í† í° ìµœì í™” ë° ì²­í‚¹ ì¤€ë¹„
            estimated_tokens = len(refined_text) * 1.5  # í•œê¸€ ê¸°ì¤€ ëŒ€ëµì  ì¶”ì •
            max_context = 28000  # ì•ˆì „ ë§ˆì§„ ê³ ë ¤
            
            chunks = []
            if estimated_tokens > max_context:
                # ì²­í‚¹ í•„ìš”
                chunk_size = int(max_context / 1.5)  # í† í° ê¸°ì¤€
                text_chunk_size = int(chunk_size / 1.5)  # ë¬¸ì ê¸°ì¤€ ì—­ì‚°
                
                current_chunk = ""
                for para in paragraphs:
                    if len(current_chunk) + len(para) < text_chunk_size:
                        current_chunk += para + "\n\n"
                    else:
                        chunks.append(current_chunk.strip())
                        current_chunk = para + "\n\n"
                
                if current_chunk:
                    chunks.append(current_chunk.strip())
            else:
                chunks = [refined_text]
            
            step4_data = {
                "original_filtered_text": filtered_text,
                "refined_text": refined_text,
                "structured_input": structured_input,
                "chunks": chunks,
                "chunk_count": len(chunks),
                "postprocessing_stats": {
                    "original_length": len(filtered_text),
                    "refined_length": len(refined_text),
                    "sentence_count": len(cleaned_sentences),
                    "paragraph_count": len(paragraphs),
                    "estimated_tokens": estimated_tokens,
                    "chunking_required": len(chunks) > 1
                },
                "optimization": {
                    "duplicate_removal": True,
                    "sentence_cleaning": True,
                    "paragraph_structuring": True,
                    "token_optimization": True
                }
            }
            save_step_result("llm_postprocessing", step4_data, 4)
            
            logger.info(f"âœ… LLM post-processing completed:")
            logger.info(f"   - Sentences: {len(cleaned_sentences)}")
            logger.info(f"   - Paragraphs: {len(paragraphs)}")
            logger.info(f"   - Chunks: {len(chunks)}")
            logger.info(f"   - Text reduction: {len(filtered_text)} â†’ {len(refined_text)} chars")
            
            # LLMì— ì „ë‹¬í•  ìµœì¢… í…ìŠ¤íŠ¸
            llm_input_text = refined_text
            
            # ========== STEP 5: íšŒì˜ë¡ ìƒì„± (ë…¸ì…˜ ê¸°íšì•ˆ) ==========
            logger.info("\nğŸ“‹ STEP 5: Generating meeting minutes (Notion project)...")
            
            async with session.post(
                f"{SERVER_URL}/generate-notion-project",
                json={
                    "transcript": llm_input_text,  # í›„ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
                    "num_tasks": 5,
                    "additional_context": "ìë™ ìƒì„±ëœ íšŒì˜ë¡"
                }
            ) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    
                    # Step 5: íšŒì˜ë¡ ê²°ê³¼ ì €ì¥
                    step5_data = {
                        "success": result.get("success"),
                        "notion_project": result.get("notion_project", {}),
                        "formatted_notion": result.get("formatted_notion", ""),
                        "metadata": {
                            "generated_at": datetime.now().isoformat(),
                            "source_text_length": len(filtered_text)
                        }
                    }
                    save_step_result("meeting_minutes", step5_data, 5)
                    
                    notion_project = result.get("notion_project", {})
                    logger.info(f"âœ… Meeting minutes generated: {notion_project.get('projectName', 'Unknown')}")
                else:
                    logger.error(f"âŒ Meeting minutes generation failed: {resp.status}")
                    notion_project = {}
            
            # ========== STEP 6: Task ë° SubTask ìƒì„± ==========
            logger.info("\nğŸ¯ STEP 6: Generating tasks and subtasks...")
            
            # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            async with session.post(
                f"{SERVER_URL}/two-stage-pipeline-text",
                json={
                    "transcript": llm_input_text,  # í›„ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
                    "generate_notion": True,
                    "generate_tasks": True,
                    "num_tasks": 5
                }
            ) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    
                    # Step 6: Task ê²°ê³¼ ì €ì¥
                    tasks_data = result.get("stage3_tasks", {})
                    if isinstance(tasks_data, dict) and "action_items" in tasks_data:
                        tasks_list = tasks_data.get("action_items", [])
                    else:
                        tasks_list = []
                    
                    step6_data = {
                        "success": result.get("success"),
                        "tasks": tasks_list,
                        "task_count": len(tasks_list),
                        "subtask_count": sum(len(task.get("subtasks", [])) for task in tasks_list),
                        "complexity_analysis": result.get("complexity_analysis", {}),
                        "processing_time": result.get("processing_time", 0),
                        "metadata": {
                            "generated_at": datetime.now().isoformat(),
                            "pipeline_version": "2-stage-with-triplet"
                        }
                    }
                    save_step_result("tasks_and_subtasks", step6_data, 6)
                    
                    logger.info(f"âœ… Generated {step6_data['task_count']} tasks with {step6_data['subtask_count']} subtasks")
                else:
                    logger.error(f"âŒ Task generation failed: {resp.status}")
            
            # ========== ìµœì¢… ìš”ì•½ ==========
            logger.info("\n" + "="*60)
            logger.info("ğŸ“Š PIPELINE EXECUTION SUMMARY")
            logger.info("="*60)
            logger.info(f"âœ… All results saved to: {SESSION_DIR}")
            logger.info(f"   - Step 1: WhisperX transcription")
            logger.info(f"   - Step 2: BERT preprocessing")
            logger.info(f"   - Step 3: BERT classification")
            logger.info(f"   - Step 4: LLM preprocessing")
            logger.info(f"   - Step 5: Meeting minutes")
            logger.info(f"   - Step 6: Tasks and subtasks")
            
            # ì „ì²´ ìš”ì•½ íŒŒì¼ ìƒì„±
            summary = {
                "session_id": timestamp,
                "audio_file": audio_file,
                "pipeline_steps": [
                    "whisperx_transcription",
                    "bert_preprocessing",
                    "bert_classification",
                    "llm_preprocessing",
                    "meeting_minutes",
                    "tasks_and_subtasks"
                ],
                "results_directory": str(SESSION_DIR),
                "execution_time": datetime.now().isoformat()
            }
            
            summary_file = SESSION_DIR / "pipeline_summary.json"
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            
            logger.info(f"\nğŸ“„ Summary saved to: {summary_file}")
            
    except Exception as e:
        logger.error(f"âŒ Pipeline error: {e}")
        import traceback
        traceback.print_exc()

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ Starting TtalKkak AI Pipeline Test")
    logger.info(f"ğŸ“ Results will be saved to: {RESULT_DIR}")
    
    # ì„œë²„ ìƒíƒœ ì²´í¬
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get("http://localhost:8000/health") as resp:
                if resp.status == 200:
                    health = await resp.json()
                    logger.info(f"âœ… Server is healthy: {health}")
                else:
                    logger.error("âŒ Server is not responding")
                    return
    except Exception as e:
        logger.error(f"âŒ Cannot connect to server: {e}")
        logger.info("ğŸ’¡ Please make sure the AI server is running:")
        logger.info("   cd ai-engine-dev && python ai_server_final_with_triplets.py")
        return
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    await test_pipeline()

if __name__ == "__main__":
    # Windowsì—ì„œ ì´ë²¤íŠ¸ ë£¨í”„ ì •ì±… ì„¤ì •
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    # ì‹¤í–‰
    asyncio.run(main())